{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d10c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial.distance import minkowski\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# FEATURE EXTRACTION FUNCTIONS\n",
    "#cropping the images into 5 different parts\n",
    "def generate_five_crops(image):\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    crops = []\n",
    "\n",
    "    crops.append(image[0:h//4, :])                \n",
    "    crops.append(image[3*h//4:h, :])              \n",
    "    crops.append(image[h//4:3*h//4, w//4:3*w//4]) \n",
    "    crops.append(image[h//4:3*h//4, 0:w//4])      \n",
    "    crops.append(image[h//4:3*h//4, 3*w//4:w])    \n",
    "\n",
    "    return crops\n",
    "#dividing the crops into 15 segments\n",
    "def divide_into_segments(crop):\n",
    "    segments = []\n",
    "    h, w, _ = crop.shape\n",
    "\n",
    "    seg_h = h // 3\n",
    "    seg_w = w // 5\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(5):\n",
    "            segment = crop[i*seg_h:(i+1)*seg_h,\n",
    "                           j*seg_w:(j+1)*seg_w]\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "#calculating the mean and std for r,g,b values\n",
    "def extract_90d_features(crop):\n",
    "    mean_rgb = np.mean(segment, axis=(0, 1))\n",
    "    std_rgb = np.std(segment, axis=(0, 1))\n",
    "\n",
    "    return mean_rgb, std_rgb\n",
    "\n",
    "#creating the 90 dimensional vector\n",
    "def build_dataset(base_path, class_names):\n",
    "    segments = divide_into_segments(crop)\n",
    "    features = []\n",
    "\n",
    "    for seg in segments:\n",
    "        mean_rgb, std_rgb = rgb_mean_std(seg)\n",
    "        features.extend(mean_rgb)\n",
    "        features.extend(std_rgb)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def build_dataset(base_path, class_names):\n",
    "    \n",
    "    X, y = [], []\n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            crops = generate_five_crops(image)\n",
    "            for crop in crops:\n",
    "                X.append(extract_90d_features(crop))\n",
    "                y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# A1\n",
    "def dot_product(vec_a, vec_b):\n",
    "    return sum(a*b for a, b in zip(vec_a, vec_b))\n",
    "\n",
    "\n",
    "def euclidean_norm(vec):\n",
    "    return np.sqrt(sum(v*v for v in vec))\n",
    "\n",
    "\n",
    "\n",
    "# A2\n",
    "def mean_vector(data):\n",
    "    return np.mean(data, axis=0)\n",
    "def std_vector(data):\n",
    "    return np.std(data, axis=0)\n",
    "\n",
    "def interclass_distance(c1, c2):\n",
    "    return np.std(data, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "# A3\n",
    "\n",
    "def feature_histogram(feature_column):\n",
    "    hist, bins = np.histogram(feature_column, bins=10)\n",
    "    return hist, bins\n",
    "\n",
    "\n",
    "\n",
    "# A4 & A5\n",
    "def minkowski_distance(vec_a, vec_b, p):\n",
    "    return sum(abs(a-b)**p for a, b in zip(vec_a, vec_b))**(1/p)\n",
    "\n",
    "\n",
    "# A10\n",
    "\n",
    "def custom_knn_predict(X_train, y_train, test_vec, k):\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        dist = minkowski_distance_custom(X_train[i], test_vec, 2)\n",
    "        distances.append((dist, y_train[i]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[:k]\n",
    "    labels = [label for _, label in neighbors]\n",
    "    return max(set(labels), key=labels.count)\n",
    "\n",
    "\n",
    "def custom_knn_batch(X_train, y_train, X_test, k):\n",
    "    return np.array([custom_knn_predict(X_train, y_train, x, k) for x in X_test])\n",
    "\n",
    "\n",
    "\n",
    "# A12 & A13\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    precision = cm[1,1] / (cm[0,1] + cm[1,1])\n",
    "    recall = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return cm, accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "# MAIN PROGRAM \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # DATASET CREATION\n",
    "    dataset_path = \"Lab2_Dataset\"\n",
    "    classes = [\"Viya\", \"Agastya\"]   \n",
    "    X, y = build_dataset(dataset_path, classes)\n",
    "\n",
    "    print(\"Dataset shape:\", X.shape)\n",
    "    print(\"Labels shape:\", y.shape)\n",
    "\n",
    "    # A1\n",
    "    A, B = X[0], X[1]\n",
    "    print(\"Dot product (custom):\", dot_product(A, B))\n",
    "    print(\"Dot product (numpy):\", np.dot(A, B))\n",
    "    print(\"Norm (custom):\", euclidean_norm(A))\n",
    "    print(\"Norm (numpy):\", np.linalg.norm(A))\n",
    "\n",
    "    # A2\n",
    "    class0, class1 = X[y==0], X[y==1]\n",
    "    centroid0, centroid1 = mean_vector(class0), mean_vector(class1)\n",
    "    print(\"Interclass distance:\", interclass_distance(centroid0, centroid1))\n",
    "\n",
    "    # A3\n",
    "    feature_data = X[:, 0]\n",
    "    hist, bins = compute_histogram(feature_data)\n",
    "    plt.hist(feature_data, bins=10)\n",
    "    plt.title(\"Histogram of Feature 0\")\n",
    "    plt.show()\n",
    "    print(\"Mean:\", np.mean(feature_data), \"Variance:\", np.var(feature_data))\n",
    "\n",
    "    # A4 & A5\n",
    "    p_vals = range(1, 11)\n",
    "    distances = [minkowski_distance_custom(A, B, p) for p in p_vals]\n",
    "    plt.plot(p_vals, distances)\n",
    "    plt.xlabel(\"p\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()\n",
    "    print(\"SciPy Minkowski (p=3):\", minkowski(A, B, 3))\n",
    "\n",
    "    # A6 to A9\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(\"kNN Accuracy:\", knn.score(X_test, y_test))\n",
    "    print(\"Predictions:\", knn.predict(X_test))\n",
    "\n",
    "    # A10 to A13\n",
    "    custom_preds = custom_knn_batch(X_train, y_train, X_test, 3)\n",
    "    cm, acc, prec, rec, f1 = compute_metrics(y_test, custom_preds)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
